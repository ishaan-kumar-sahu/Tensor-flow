{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport glob\nimport os \nimport numpy as np # linear algebra\nimport pandas as pan # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plotter\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T11:43:55.698579Z","iopub.execute_input":"2023-09-13T11:43:55.699597Z","iopub.status.idle":"2023-09-13T11:44:04.896929Z","shell.execute_reply.started":"2023-09-13T11:43:55.699562Z","shell.execute_reply":"2023-09-13T11:44:04.895764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Brains. <h2/>","metadata":{}},{"cell_type":"code","source":"#walk the images\nMASTER = \"//kaggle//input//brain-mri-images-for-brain-tumor-detection\"\nimages = [i for i in glob.glob(MASTER +\"//*//*\")]#trying to be very incomprehensible here\nnp.random.shuffle(images)\nimage_labels = [os.path.dirname(i).split(\"/\")[-1] for i in images]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:04.899378Z","iopub.execute_input":"2023-09-13T11:44:04.900073Z","iopub.status.idle":"2023-09-13T11:44:04.950351Z","shell.execute_reply.started":"2023-09-13T11:44:04.900038Z","shell.execute_reply":"2023-09-13T11:44:04.949327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#zip into df for visualization and stuff\nimage_with_labels = zip(images, image_labels)\ncols = [\"Images\", \"Labels\"]\ndata_frame = pan.DataFrame(image_with_labels, columns = cols)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:04.952766Z","iopub.execute_input":"2023-09-13T11:44:04.953443Z","iopub.status.idle":"2023-09-13T11:44:04.961823Z","shell.execute_reply.started":"2023-09-13T11:44:04.953402Z","shell.execute_reply":"2023-09-13T11:44:04.960638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = data_frame[\"Labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:04.963631Z","iopub.execute_input":"2023-09-13T11:44:04.964030Z","iopub.status.idle":"2023-09-13T11:44:05.466790Z","shell.execute_reply.started":"2023-09-13T11:44:04.963985Z","shell.execute_reply":"2023-09-13T11:44:05.465656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_frame = data_frame[data_frame[\"Labels\"] != \"brain_tumor_dataset\"]\nsns.countplot(x = data_frame[\"Labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:05.470129Z","iopub.execute_input":"2023-09-13T11:44:05.470503Z","iopub.status.idle":"2023-09-13T11:44:05.737581Z","shell.execute_reply.started":"2023-09-13T11:44:05.470467Z","shell.execute_reply":"2023-09-13T11:44:05.736521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see some stuff\ntest_arr = plotter.imread(data_frame.iloc[19][\"Images\"])\nplotter.imshow(test_arr)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:05.739287Z","iopub.execute_input":"2023-09-13T11:44:05.739653Z","iopub.status.idle":"2023-09-13T11:44:06.102689Z","shell.execute_reply.started":"2023-09-13T11:44:05.739602Z","shell.execute_reply":"2023-09-13T11:44:06.101577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seems the image sizes are rather large in general, resizing to around 300, 300 should do the trick\nIMG_SIZE = (300, 300, 1)#it's black and white, right???\n#again, anyone is welcome to fork and visualize\n#encode the label\nmapper = {label: num for num, label in enumerate(data_frame[\"Labels\"].unique())}\n#train-test-split next\nfeatures = data_frame[\"Images\"]\nlabel = data_frame[\"Labels\"].map(mapper)\nfeature_train, feature_test, label_train, label_test = train_test_split(features, label, test_size = 0.2, random_state = 42)\n\n#define preprocessing pipeline\ndef preprocessor(image, label):\n    apply_effect = tf.random.uniform([]) < 0.2\n    image = tf.io.read_file(image)\n    image = tf.image.decode_jpeg(image, channels = 1)\n    image = tf.image.resize(image, IMG_SIZE[: 2])\n    image = tf.image.stateless_random_brightness(image, max_delta = 0.2, seed = (42, 101))\n    image = tf.cond(apply_effect, lambda : tf.image.stateless_random_flip_up_down(image, seed = (42, 101)), lambda: image)\n    image = tf.cond(apply_effect, lambda: tf.image.stateless_random_flip_left_right(image, seed = (42, 101)), lambda: image)\n    image = image/255\n    return image, tf.one_hot(label, depth = 1) #[0, 1], [1, 0], right?\n\n#create dataset objects from np arrays, zip, then apply transformation\nfeature_train_dataset = tf.data.Dataset.from_tensor_slices(feature_train)\nfeature_test_dataset = tf.data.Dataset.from_tensor_slices(feature_test)\nlabel_train_dataset = tf.data.Dataset.from_tensor_slices(label_train)\nlabel_test_dataset = tf.data.Dataset.from_tensor_slices(label_test)\n\ntrain = tf.data.Dataset.zip((feature_train_dataset, label_train_dataset))\ntest = tf.data.Dataset.zip((feature_test_dataset, label_test_dataset))\n\ntrain = train.map(preprocessor).batch(64).shuffle(128).prefetch(128)\ntest = test.map(preprocessor).batch(128).prefetch(128)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:06.103841Z","iopub.execute_input":"2023-09-13T11:44:06.104217Z","iopub.status.idle":"2023-09-13T11:44:09.481748Z","shell.execute_reply.started":"2023-09-13T11:44:06.104184Z","shell.execute_reply":"2023-09-13T11:44:09.480510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build model\nimage_learner = Sequential()\nimage_learner.add(Conv2D(16, (2, 2), activation = \"relu\", input_shape = IMG_SIZE))\nimage_learner.add(MaxPool2D((2, 2)))\nimage_learner.add(Conv2D(32, (2, 2), activation = \"relu\"))\nimage_learner.add(MaxPool2D((2, 2)))\nimage_learner.add(Conv2D(64, (2, 2), activation = \"relu\"))\nimage_learner.add(MaxPool2D((2, 2)))\nimage_learner.add(Flatten())\nimage_learner.add(Dense(units = 128, activation = \"relu\"))\nimage_learner.add(Dense(units = 1, activation = \"sigmoid\"))\n\noptimizer = Adam(learning_rate = 1e-3)\nimage_learner.compile(loss = \"binary_crossentropy\", metrics = [\"accuracy\"], optimizer = optimizer)\nimage_learner.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:09.483094Z","iopub.execute_input":"2023-09-13T11:44:09.483446Z","iopub.status.idle":"2023-09-13T11:44:09.658416Z","shell.execute_reply.started":"2023-09-13T11:44:09.483402Z","shell.execute_reply":"2023-09-13T11:44:09.657636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(patience = 3)\nimage_learner.fit(train, validation_data = test, callbacks = [es], epochs = 25)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:09.659411Z","iopub.execute_input":"2023-09-13T11:44:09.659754Z","iopub.status.idle":"2023-09-13T11:44:27.919808Z","shell.execute_reply.started":"2023-09-13T11:44:09.659722Z","shell.execute_reply":"2023-09-13T11:44:27.918098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_learner.evaluate(test)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:44:27.921189Z","iopub.execute_input":"2023-09-13T11:44:27.921568Z","iopub.status.idle":"2023-09-13T11:44:28.109593Z","shell.execute_reply.started":"2023-09-13T11:44:27.921533Z","shell.execute_reply":"2023-09-13T11:44:28.108540Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}